<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>1.2.3. Compute Bayes rule &mdash; PSL_Book 0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=2709fde1"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1.2.4. Discussion" href="w1_2_discussion.html" />
    <link rel="prev" title="1.2.2. Simulation Study" href="w1_2_simulation_study.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            PSL_Book
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="w1_index.html">1. Introduction</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="w1_1_index.html">1.1. Introduction to statistical learning</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="w1_2_index.html">1.2. Least squares vs. nearest neighbors</a><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="w1_2_intro_LS_kNN.html">1.2.1. Introduction to LS and kNN</a></li>
<li class="toctree-l3"><a class="reference internal" href="w1_2_simulation_study.html">1.2.2. Simulation Study</a></li>
<li class="toctree-l3 current"><a class="current reference internal" href="#">1.2.3. Compute Bayes rule</a></li>
<li class="toctree-l3"><a class="reference internal" href="w1_2_discussion.html">1.2.4. Discussion</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../w2/w2_index.html">2. Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w3/w3_index.html">3. Variable Selection and Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w4/w4_index.html">4. Regression Trees and Ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w5/w5_index.html">5. Nonlinear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w6/w6_index.html">6. Clustering Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w7/w7_index.html">7. Latent Structure Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w8/w8_index.html">8. TBA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w9/w9_index.html">9. Discriminant Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w10/w10_index.html">10. Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w11/w11_index.html">11. Support Vector Machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w12/w12_index.html">12. Classification Trees and Boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w13/w13_index.html">13. Recommender System</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PSL_Book</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="w1_index.html"><span class="section-number">1. </span>Introduction</a></li>
          <li class="breadcrumb-item"><a href="w1_2_index.html"><span class="section-number">1.2. </span>Least squares vs. nearest neighbors</a></li>
      <li class="breadcrumb-item active"><span class="section-number">1.2.3. </span>Compute Bayes rule</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/w1/w1_2_bayes_rule.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="compute-bayes-rule">
<h1><span class="section-number">1.2.3. </span>Compute Bayes rule<a class="headerlink" href="#compute-bayes-rule" title="Link to this heading"></a></h1>
<p>The Bayes classification rule is derived from Bayes’ Theorem. Below is the probabilistic description of the data generating process for Example 1. The first line defines the distribution of Y, while the following two lines describe the conditional distribution of X given Y. Multiplying them provides the joint distribution of X and Y.</p>
<div class="math notranslate nohighlight">
\[\begin{split}Y                       &amp;\sim \textsf{Bern}(p), \\
X \mid  Y=0 &amp;\sim \textsf{N}(\mu_0, \sigma^2 \mathbf{I}_2), \\
X \mid  Y=1 &amp;\sim  \textsf{N}(\mu_1, \sigma^2 \mathbf{I}_2).\end{split}\]</div>
<p>For predictions, we care about Y given X, the conditional probability. Since Y takes only two possible values, knowing the probability of Y = 1 given X is enough for us to form our best prediction for Y.</p>
<p>Before applying the Bayes’ theorem to compute this conditional probability, I want to clarify some terms.</p>
<p>We often discuss two types of random variables in class:</p>
<ul class="simple">
<li><p><strong>Discrete Random Variables</strong>: Like Y in our example, we describe its distribution using a probability mass function (PMF).</p></li>
<li><p><strong>Continuous Random Variables</strong>: Like X,  we describe its distribution using a probability density function (PDF). For example, the PDf of a normal distribution is bell-shaped.</p></li>
</ul>
<p>The joint distribution of X and Y here presents a challenge because it’s neither purely discrete nor continuous. For discrete variables, we can discuss probabilities of specific values (e.g., Y=1). For continuous variables, however, the probability of a specific value is always zero. In the derivation below,  I’ll treat X as discrete, utilizing its density function as the corresponding PMF; this can be justified by discretizing a continuous variable.</p>
<p>The conditional probability is calculated as the joint divided by the marginal.</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp; P(Y=1 \mid X=x) = \frac{P(Y=1, X=x)}{P(X=x)} \\
= &amp; \frac{P(Y=1, X=x)}{P(Y=1, X=x) + P(Y=0, X=x)} \\
=&amp;  \frac{P(Y=1) P( X=x | Y=1)}{P(Y=1) P( X=x | Y=1) + P(Y=0) P( X=x | Y=0)} \\
=&amp; \frac{(p) \left ( \frac{1}{\sqrt{2 \pi \sigma^2}} \right)^2 \exp \big \{ - \frac{\| x - \mu_1\|^2}{2 \sigma^2}\big \}}{(p) \left ( \frac{1}{\sqrt{2 \pi \sigma^2}} \right)^2 \exp \big \{ - \frac{\| x - \mu_1\|^2}{2 \sigma^2}\big \} + (1-p) \left ( \frac{1}{\sqrt{2 \pi \sigma^2}} \right)^2 \exp \big \{ - \frac{\| x - \mu_0\|^2}{2 \sigma^2}\big \}} \\
=&amp; \left [ 1 +  \exp \Big \{ \frac{1}{2 \sigma^2} ( \| x- \mu_1\|^2 - \| x - \mu_0\|^2) - \log \frac{p}{1-p} \Big \}  \right ]^{-1}\end{split}\]</div>
<p>After simplifying, the conditional probability is found to be a specific expression. This helps us establish the the optimal decision rule (i.e., the Bayes rule) for classification,</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp;  P(Y=1 \mid X=x)  &gt; 0.5 \\
\Longleftrightarrow &amp; \frac{1}{2 \sigma^2} ( \| x- \mu_1\|^2 - \| x - \mu_0\|^2) &lt; \log \frac{p}{1-p}\end{split}\]</div>
<p>If p=0.5,  log p/(1-p)=0, then we basically predict Y=1 if <span class="math notranslate nohighlight">\(\| x - \mu_1\|^2 &lt;  \| x - \mu_0\|^2\)</span>. That is, we predict x to be class 1 if it’s close to the center of class 1 and 0 if it’s closer to the center of class 0.</p>
<p>The decision rule looks like a quadratic function of x, but it can be simplied as a linear function of x (i.e., the optimal decision boundary for Example 1 is linear):</p>
<div class="math notranslate nohighlight">
\[\begin{split}&amp; \| x - \mu_1\|^2 - \| x - \mu_0\|^2 \\
= &amp;  \| x\|^2 - 2 x^t \mu_1 + \| \mu_1\|^2 - ( \| x\|^2 - 2 x^t \mu_0 + \| \mu_0\|^2) \\
= &amp; \| \mu_1\|^2 -  \| \mu_0\|^2 - 2 x^t (\mu_1 - \mu_0)\end{split}\]</div>
<p>You will be asked to implement the Bayes rule for Example 2, where given Y = 1, follows a mixture of 10 normal distributions. The derivation remains roughly the same, except that you need to replace the PDF of X given by Y by an average of 10 normals.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="w1_2_simulation_study.html" class="btn btn-neutral float-left" title="1.2.2. Simulation Study" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="w1_2_discussion.html" class="btn btn-neutral float-right" title="1.2.4. Discussion" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Feng Liang.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>