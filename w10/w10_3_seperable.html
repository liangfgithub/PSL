<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>10.3. Seperable Data &mdash; PSL_Book 0.1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=2709fde1"></script>
        <script src="../_static/doctools.js?v=888ff710"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="10.4. Logistic Regression in R/Python" href="w10_4_code.html" />
    <link rel="prev" title="10.2. MLE" href="w10_2_mle.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            PSL_Book
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../w1/w1_index.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w2/w2_index.html">2. Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w3/w3_index.html">3. Variable Selection and Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w4/w4_index.html">4. Regression Trees and Ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w5/w5_index.html">5. Nonlinear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w6/w6_index.html">6. Clustering Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w7/w7_index.html">7. Latent Structure Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w8/w8_index.html">8. TBA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w9/w9_index.html">9. Discriminant Analysis</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="w10_index.html">10. Logistic Regression</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="w10_1_setup.html">10.1. Setup</a></li>
<li class="toctree-l2"><a class="reference internal" href="w10_2_mle.html">10.2. MLE</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">10.3. Seperable Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="w10_4_code.html">10.4. Logistic Regression in R/Python</a></li>
<li class="toctree-l2"><a class="reference internal" href="w10_5_varsel.html">10.5. Variable Selection</a></li>
<li class="toctree-l2"><a class="reference internal" href="w10_6_sampling.html">10.6. Retrospective Sampling Data</a></li>
<li class="toctree-l2"><a class="reference internal" href="w10_7_nonlinear.html">10.7. Nonlinear Logistic Regression</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../w11/w11_index.html">11. Support Vector Machine</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w12/w12_index.html">12. Classification Trees and Boosting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w13/w13_index.html">13. Recommender System</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PSL_Book</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="w10_index.html"><span class="section-number">10. </span>Logistic Regression</a></li>
      <li class="breadcrumb-item active"><span class="section-number">10.3. </span>Seperable Data</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="seperable-data">
<h1><span class="section-number">10.3. </span>Seperable Data<a class="headerlink" href="#seperable-data" title="Link to this heading"></a></h1>
<p>Let’s address a minor issue that can arise in logistic regression when dealing with well-separated data.</p>
<p>What do we mean by “well-separated data”? Consider the toy example where the two red points belong to class one, two blue points belong to class zero, and the data is two-dimensional. In this case, we’ll simplify by assuming that the intercept is zero, and our objective is to determine the regression coefficients <span class="math notranslate nohighlight">\(\beta_1\)</span> and <span class="math notranslate nohighlight">\(\beta_2.\)</span></p>
<a class="reference internal image-reference" href="../_images/w10_separable_toy_data.png"><img alt="../_images/w10_separable_toy_data.png" src="../_images/w10_separable_toy_data.png" style="width: 513.1500000000001px; height: 303.05px;" /></a>
<p>Now, let’s examine the log-likelihood. For the likelihood calculation, the expression for red points is shown in the red box, while for blue points, it’s shown in the blue box. The crucial difference is the presence of a <strong>minus sign</strong> in front of the exponential component for the red points, which is absent in the blue box.</p>
<p>Initially, let’s set <span class="math notranslate nohighlight">\(\beta_1 = 1, \beta_2 = 1.\)</span> For the red points, since they are in the first quadrant, the exponential component X1+X2 will be positive. Thus, this ratio is less than one, making the probability larger than 0.5. Similarly, for the two blue points in the third quadrant, both X1 and X2 are negative, resulting in a probability larger than 0.5.</p>
<p>Next, let’s experiment with increasing beta values: <span class="math notranslate nohighlight">\(\beta_1 = 10, \beta_2 = 10.\)</span> Repeating the calculations, we observe that the exponential component is significantly smaller than one for both red and blue points. Again, the probabilities are well above 0.5. This suggests that higher values of beta result in even better likelihoods.</p>
<p>Continuing this exploration, we set  <span class="math notranslate nohighlight">\(\beta_1 = 500, \beta_2 = 500.\)</span> Now the exponential component becomes very negative. Consequently, the probabilities approach one, moving closer to the desired outcome. It appears that we can continually increase these coefficients to maximize the likelihood.</p>
<p>Herein lies the problem: when data are well separated, there is no limit to how large you can make the coefficients to push the probabilities in the desired direction. This causes logistic regression algorithms to fail to converge. In R, for example, you may receive a warning message about non-convergence.</p>
<p>However, it’s important to note that this doesn’t render the model entirely useless. While there may be multiple coefficient sets, the decision boundary, the line that separates the classes, is still well-defined. In this toy example, despite the coefficients growing exponentially, the decision boundary remains constant, which is the line corresponding to X1+X2=0, or equivalently 10(X1 + X2) = 0 or 500(X1 + X2) = 0.</p>
<p>In summary, logistic regression can encounter convergence issues when dealing with well-separated data because the coefficients may grow without bound in an attempt to maximize the likelihood. While this poses a challenge for inference on the beta parameters, it doesn’t necessarily invalidate the model’s usefulness for making predictions, as the decision boundary remains consistent.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="w10_2_mle.html" class="btn btn-neutral float-left" title="10.2. MLE" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="w10_4_code.html" class="btn btn-neutral float-right" title="10.4. Logistic Regression in R/Python" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Feng Liang.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>