<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>12.3. Misclassification Rate vs. Entropy &mdash; PSL_Book 0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../_static/jquery.js?v=5d32c60e"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../_static/documentation_options.js?v=2709fde1"></script>
        <script src="../_static/doctools.js?v=9a2dae69"></script>
        <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="12.4. AdaBoosting" href="w12_4_aAaboost.html" />
    <link rel="prev" title="12.2. Impurity Measures" href="w12_2_measures.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            PSL_Book
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../w1/w1_index.html">1. Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w2/w2_index.html">2. Linear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w3/w3_index.html">3. Variable Selection and Regularization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w4/w4_index.html">4. Regression Trees and Ensemble</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w5/w5_index.html">5. Nonlinear Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w6/w6_index.html">6. Clustering Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w7/w7_index.html">7. Latent Structure Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w8/w8_index.html">8. TBA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w9/w9_index.html">9. Discriminant Analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w10/w10_index.html">10. Logistic Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="../w11/w11_index.html">11. Support Vector Machine</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="w12_index.html">12. Classification Trees and Boosting</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="w12_1_intro.html">12.1. Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="w12_2_measures.html">12.2. Impurity Measures</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">12.3. Misclassification Rate vs. Entropy</a></li>
<li class="toctree-l2"><a class="reference internal" href="w12_4_aAaboost.html">12.4. AdaBoosting</a></li>
<li class="toctree-l2"><a class="reference internal" href="w12_5_boost.html">12.5. Forward Stagewise Additive Modeling</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../w13/w13_index.html">13. Recommender System</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">PSL_Book</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="w12_index.html"><span class="section-number">12. </span>Classification Trees and Boosting</a></li>
      <li class="breadcrumb-item active"><span class="section-number">12.3. </span>Misclassification Rate vs. Entropy</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="misclassification-rate-vs-entropy">
<h1><span class="section-number">12.3. </span>Misclassification Rate vs. Entropy<a class="headerlink" href="#misclassification-rate-vs-entropy" title="Link to this heading"></a></h1>
<p>Now, let’s delve into the mathematical distinctions between the
misclassification rate and entropy, two commonly used impurity measures in
classification trees.</p>
<p>To illustrate these differences, let’s consider a hypothetical scenario where we partition a set of n observations within a node t into two child nodes: left and right, containing n_L and n_R observations, respectively.</p>
<p>For simplicity, we’ll assume there are only two classes. In the case of two classes,  the impurity measure can be expressed as a function of the percentage of samples in one class. Let’s denote the percentage of class zero as <span class="math notranslate nohighlight">\(p_t\)</span>
at a node t. This impurity function is essentially a function of
<span class="math notranslate nohighlight">\(p_t\)</span>. The gain of the impurity measure is then determined by the difference in impurity at node t (without a split) and the weighted sum of impurities in the left and right nodes. The weights are proportional to the sample sizes in the respective nodes.</p>
<div class="math notranslate nohighlight">
\[\begin{split}\Phi(j,s) &amp; = i(t) - \big [ p_R \cdot i(t_R)  + p_L \cdot i(t_L)  \big ] \\
&amp; = f(p_t) - \Big [ \frac{n_R}{n_R + n_L} \cdot f(p_{t_R}) + \frac{n_L}{n_R + n_L} \cdot f(p_{t_L}) \Big ]\end{split}\]</div>
<p>Importantly, we observe that the percentage of class zero at the parent node t is equal to the weighted sum of the percentage of class one in the two child nodes. This equality arises due to the weights being determined by the sample sizes in each node.</p>
<div class="math notranslate nohighlight">
\[\begin{split}p_t &amp; = \frac{n_R \cdot p_{t_R} + n_L \cdot p_{t_L}}{n_R + n_L} \\
                &amp; = \left ( \frac{n_R}{n_R + n_L} \right ) \cdot p_{t_R} + \left ( \frac{n_L}{n_R + n_L} \right ) \dot p_{t_L}.\end{split}\]</div>
<p>The goodness of split <span class="math notranslate nohighlight">\(\Phi(j,s)\)</span> can be represented as the discrepancy between the function evaluated at a weighted sum of <span class="math notranslate nohighlight">\(p_{t_R}\)</span> and <span class="math notranslate nohighlight">\(p_{t_L}\)</span>, and the weighted sum of the function evaluated at <span class="math notranslate nohighlight">\(p_{t_R}\)</span> and <span class="math notranslate nohighlight">\(p_{t_L}\)</span>.</p>
<p>Crucially, the gain in the impurity measure will be positive if the function f is strictly concave. This property ensures that the difference between impurity measures at the parent node and the child nodes is always positive when evaluating the gain.</p>
<p>Let’s consider the following example:</p>
<a class="reference internal image-reference" href="../_images/w12_example.png"><img alt="../_images/w12_example.png" src="../_images/w12_example.png" style="width: 699.2px; height: 328.0px;" /></a>
<p>To illustrate this concept visually, consider the plot below. It  shows the misclassification rate and entropy as functions of p, representing the percentage of one class. The misclassification rate (blue curve) is piecewise linear, while entropy (red curve) is strictly concave. The scaling is adjusted to ensure that both the entropy and the misclassification rate have the same value at p = 0.5.</p>
<a class="reference internal image-reference" href="../_images/w12_concave.png"><img alt="../_images/w12_concave.png" src="../_images/w12_concave.png" style="width: 653.8px; height: 246.39999999999998px;" /></a>
<p>As mentioned earlier, when calculating the gain in the impurity measure, we compare the impurity measures at the parent node (blue dot) and the child nodes (green dot) as represented by the red and blue curves. If the underlying function is strictly concave (as in the case of entropy), the difference is always positive.</p>
<p>However, if both p1 and p2 fall on the same side of 0.5 (for instance, both on the left side), using the misclassification rate results in a zero gain because there is no additional benefit gained from the split. Conversely, entropy (and Gini index) consistently yield positive gains, encouraging the creation of pure nodes.</p>
<p>In summary, when constructing the tree, it is advisable to use either entropy or the Gini index as impurity measures because they are strictly concave functions. They encourage the creation of pure nodes. However, during the pruning phase, you have the flexibility to use the misclassification rate or any other impurity measure that suits your specific goals.</p>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="w12_2_measures.html" class="btn btn-neutral float-left" title="12.2. Impurity Measures" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="w12_4_aAaboost.html" class="btn btn-neutral float-right" title="12.4. AdaBoosting" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Feng Liang.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>